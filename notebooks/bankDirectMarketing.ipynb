{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Example\n",
    "## Bank dataset to determine if a customer would buy a CD\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution.  The marketing campaigns were based on phone calls.  A number of features such as age, kind of job, marital status, education level, credit default, existence of housing loan, etc. were considered.  The classification goal is to predict if the client will subscribe (yes/no) a term deposit.\n",
    "\n",
    "More information regarding the data set is at https://archive.ics.uci.edu/ml/datasets/bank+marketing#.\n",
    "\n",
    "<font color='blue'>__ The objective is to demonstrate the use of logistic regression and to tune hyperparameters enet_lamba and enet_alpha. __</font>\n",
    "\n",
    "## Attribute Information:\n",
    "\n",
    "### Input variables:\n",
    "#### Bank client data:\n",
    "1. age (numeric)\n",
    "2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4. education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5. default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6. housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7. loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "#### Related with the last contact of the current campaign:\n",
    "8. contact: contact communication type (categorical: 'cellular','telephone') \n",
    "9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "#### Other attributes:\n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "#### Social and economic context attributes:\n",
    "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17. cons.price.idx: consumer price index - monthly indicator (numeric) \n",
    "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric) \n",
    "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20. nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "### Output variable (desired target):\n",
    "21. y - has the client subscribed a term deposit? (binary: 'yes','no')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "Set up the imports, logging, and loading of the data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal import clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hana_ml.algorithms.pal import trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The data is loaded into 3 tables, one for the test set, another for the training set, and finally the validation set:\n",
    "<li>DBM2_RTEST_TBL</li>\n",
    "<li>DBM2_RTRAINING_TBL</li>\n",
    "<li>DBM2_RVALIDATION_TBL</li>\n",
    "\n",
    "To do that, a connection is created and passed to the loader.\n",
    "\n",
    "There is a config file, config/e2edata.ini that controls the connection parameters and whether or not to reload the data from scratch.  In case the data is already loaded, there would be no need to load the data.  A sample section is below.  If the config parameter, reload_data is true then the tables for test, training, and validation are (re-)created and data inserted into them.\n",
    "\n",
    "Although this ini file has other sections, please do not modify them. Only the [hana] section should be modified.\n",
    "\n",
    "#########################<br>\n",
    "[hana]<br>\n",
    "url=host.sjc.sap.corp<br>\n",
    "user=username<br>\n",
    "passwd=userpassword<br>\n",
    "port=3xx15<br>\n",
    "#########################<br>"
   ]
  },
  {
   "source": [
    "https://blogs.sap.com/2020/01/16/hana-ml-dataframe-end-to-end-methods-and-its-usage/\n",
    "\n",
    "https://blogs.sap.com/2019/09/03/association-algorithms-hana-ml-apis/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load_utils import DataSets, Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url, port, user, pwd, schema, cert = Settings.load_config(\"../config/e2edata.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cert = \"-----BEGIN CERTIFICATE-----MIIDrzCCApegAwIBAgIQCDvgVpBCRrGhdWrJWZHHSjANBgkqhkiG9w0BAQUFADBhMQswCQYDVQQGEwJVUzEVMBMGA1UEChMMRGlnaUNlcnQgSW5jMRkwFwYDVQQLExB3d3cuZGlnaWNlcnQuY29tMSAwHgYDVQQDExdEaWdpQ2VydCBHbG9iYWwgUm9vdCBDQTAeFw0wNjExMTAwMDAwMDBaFw0zMTExMTAwMDAwMDBaMGExCzAJBgNVBAYTAlVTMRUwEwYDVQQKEwxEaWdpQ2VydCBJbmMxGTAXBgNVBAsTEHd3dy5kaWdpY2VydC5jb20xIDAeBgNVBAMTF0RpZ2lDZXJ0IEdsb2JhbCBSb290IENBMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4jvhEXLeqKTTo1eqUKKPC3eQyaKl7hLOllsBCSDMAZOnTjC3U/dDxGkAV53ijSLdhwZAAIEJzs4bg7/fzTtxRuLWZscFs3YnFo97nh6Vfe63SKMI2tavegw5BmV/Sl0fvBf4q77uKNd0f3p4mVmFaG5cIzJLv07A6Fpt43C/dxC//AH2hdmoRBBYMql1GNXRor5H4idq9Joz+EkIYIvUX7Q6hL+hqkpMfT7PT19sdl6gSzeRntwi5m3OFBqOasv+zbMUZBfHWymeMr/y7vrTC0LUq7dBMtoM1O/4gdW7jVg/tRvoSSiicNoxBN33shbyTApOB6jtSj1etX+jkMOvJwIDAQABo2MwYTAOBgNVHQ8BAf8EBAMCAYYwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUA95QNVbRTLtm8KPiGxvDl7I90VUwHwYDVR0jBBgwFoAUA95QNVbRTLtm8KPiGxvDl7I90VUwDQYJKoZIhvcNAQEFBQADggEBAMucN6pIExIK+t1EnE9SsPTfrgT1eXkIoyQY/EsrhMAtudXH/vTBH1jLuG2cenTnmCmrEbXjcKChzUyImZOMkXDiqw8cvpOp/2PV5Adg06O/nVsJ8dWO41P0jmP6P6fbtGbfYmbW0W5BjfIttep3Sp+dWOIrWcBAI+0tKIJFPnlUkiaY4IBIqDfv8NZ5YBberOgOzW6sRBc4L0na4UU+Krk2U886UAb3LujEV0lsYSEY1QSteDwsOoBrp+uvFRTp2InBuThs4pFsiv9kuXclVzDAGySj4dzp30d8tbQkCAUw7C29C79Fv1C5qfPrmAESrciIxpg0X40KPMbp1ZWVbd4=-----END CERTIFICATE-----\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection_context = dataframe.ConnectionContext(url, port, user, pwd)"
   ]
  },
  {
   "source": [
    "https://help.sap.com/viewer/0eec0d68141541d1b07893a39944924e/latest/en-US/ee592e89dcce4480a99571a4ae7a702f.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_context = dataframe.ConnectionContext(address=url, port=int(port), user=user, password=pwd, currentSchema=schema, encrypt=\"true\", sslValidateCertificate=\"true\", sslCryptoProvider=\"openssl\", sslTrustStore=cert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating table DM_PAL.DBM2_RFULL_TBL\n",
      "Creating table DM_PAL.DBM2_RTRAINING_TBL\n",
      "Creating table DM_PAL.DBM2_RVALIDATION_TBL\n",
      "Creating table DM_PAL.DBM2_RTEST_TBL\n"
     ]
    }
   ],
   "source": [
    "full_tbl, training_tbl, validation_tbl, test_tbl = DataSets.load_bank_data(connection_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Frames\n",
    "Create the data frames for the full, test, training, and validation sets.\n",
    "\n",
    "Let us also do some data exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Datasets - Training, validation, and test sets\n",
    "Data frames are used keep references to data so computation on large data sets in HANA can happen in HANA.  Trying to bring the entire data set into the client will likely result in out of memory exceptions.\n",
    "\n",
    "The original/full dataset is split into training, test and validation sets.  In the example below, they reside in different tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ping ld5501.wdf.sap.corp\n",
    "#from pythonping import ping\n",
    "#ping('ld5501.wdf.sap.corp', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = connection_context.table(full_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = connection_context.table(training_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = connection_context.table(validation_tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = connection_context.table(test_tbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Exploration\n",
    "Let us look at the number of rows in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Number of rows in full set: {}'.format(full_set.count()))\n",
    "print('Number of rows in training set: {}'.format(training_set.count()))\n",
    "print('Number of rows in validation set: {}'.format(validation_set.count()))\n",
    "print('Number of rows in test set: {}'.format(test_set.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ping ld5501.wdf.sap.corp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['AGE','JOB','MARITAL','EDUCATION','DBM_DEFAULT', 'HOUSING','LOAN','CONTACT','DBM_MONTH','DAY_OF_WEEK','DURATION','CAMPAIGN','PDAYS','PREVIOUS','POUTCOME','EMP_VAR_RATE','CONS_PRICE_IDX','CONS_CONF_IDX','EURIBOR3M','NREMPLOYED']\n",
    "label = \"LABEL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us look at some rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.filter(\"\\\"LABEL\\\"='yes'\").head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model and Tune Hyperparameters\n",
    "Try different hyperparameters and see what parameter is best.\n",
    "The results are stored in a list called res which can then be used to visualize the results.\n",
    "\n",
    "_The variable \"quick\" is to run the tests for only a few values to avoid running the code below for a long time._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick = True\n",
    "enet_lambdas = np.linspace(0.01,0.02, endpoint=False, num=1) if quick else np.append(np.linspace(0.01,0.02, endpoint=False, num=4), np.linspace(0.02,0.02, num=5))\n",
    "enet_alphas = np.linspace(0, 1, num=4) if quick else np.linspace(0, 1, num=40)\n",
    "res = []\n",
    "for enet_alpha in enet_alphas:\n",
    "    for enet_lambda in enet_lambdas:\n",
    "        lr = linear_model.LogisticRegression(connection_context, solver='Cyclical', tol=0.000001, max_iter=10000, \n",
    "                                               stat_inf=True,pmml_export='multi-row', lamb=enet_lambda, alpha=enet_alpha,\n",
    "                                               class_map0='no', class_map1='yes')\n",
    "        lr.fit(training_set, features=features, label=label)\n",
    "        accuracy_val = lr.score(validation_set, 'ID', features, label)\n",
    "        res.append((enet_alpha, enet_lambda, accuracy_val, lr.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph the results\n",
    "Plot the accuracy on the validation set against the hyperparameters.\n",
    "\n",
    "This is only done if all the combinations are tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "if not quick:\n",
    "    arry = np.asarray(res)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.title(\"Validation accuracy for training set with different lambdas\")\n",
    "    ax = fig.add_subplot(111)\n",
    "    most_accurate_lambda = arry[np.argmax(arry[:,2]),1]\n",
    "    best_accuracy_arg = np.argmax(arry[:,2])\n",
    "    for lamda in enet_lambdas:\n",
    "        if lamda == most_accurate_lambda:\n",
    "            ax.plot(arry[arry[:,1]==lamda][:,0], arry[arry[:,1]==lamda][:,2], label=\"%.3f\" % round(lamda,3), linewidth=5, c='r')\n",
    "        else:\n",
    "            ax.plot(arry[arry[:,1]==lamda][:,0], arry[arry[:,1]==lamda][:,2], label=\"%.3f\" % round(lamda,3))\n",
    "    plt.legend(loc=1, title=\"Legend (Lambda)\", fancybox=True, fontsize=12)\n",
    "    ax.set_xlabel('Alpha', fontsize=12)\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(\"Best accuracy: %.4f\" % (arry[best_accuracy_arg][2]))\n",
    "    print(\"Value of alpha for maximum accuracy: %.3f\\nValue of lambda for maximum accuracy: %.3f\\n\" % (arry[best_accuracy_arg][0], arry[best_accuracy_arg][1]))\n",
    "else:\n",
    "    display(Image('images/bank-data-hyperparameter-tuning.png', width=800, unconfined=True))\n",
    "    print(\"Best accuracy: 0.9148\")\n",
    "    print(\"Value of alpha for maximum accuracy: 0.769\")\n",
    "    print(\"Value of lambda for maximum accuracy: 0.010\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on test set\n",
    "Let us do the predictions on the test set using these values of alpha and lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.769\n",
    "lamda = 0.01\n",
    "lr = linear_model.LogisticRegression(connection_context, solver='Cyclical', tol=0.000001, max_iter=10000, \n",
    "                                       stat_inf=True,pmml_export='multi-row', lamb=lamda, alpha=alpha,\n",
    "                                       class_map0='no', class_map1='yes')\n",
    "lr.fit(training_set, features=features, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the coefficients\n",
    "The coefficients are again a data frame. So, we sort and get the top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.coef_.sort(\"COEFFICIENT\", desc=True).head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = lr.predict(test_set, 'ID')\n",
    "result_df.filter('\"CLASS\"=\\'no\\'').head(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.filter('\"CLASS\"=\\'yes\\'').head(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about the final score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(test_set, 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}